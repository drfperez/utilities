{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drfperez/utilities/blob/main/Webtopdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "usvXeB9tJf0a",
        "outputId": "933e432e-7b8f-4a90-e130-55514ed87dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Instal¬∑lant depend√®ncies necess√†ries...\n",
            "‚úÖ Depend√®ncies instal¬∑lades correctament\n",
            "üîß Inicialitzant sistema de conversi√≥ web a PDF...\n",
            "\n",
            "        ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "        ‚ïë                                                       ‚ïë\n",
            "        ‚ïë    üåê SISTEMA DE CONVERSI√ì WEB A PDF                 ‚ïë\n",
            "        ‚ïë          per Google Colab                            ‚ïë\n",
            "        ‚ïë                                                       ‚ïë\n",
            "        ‚ïë    Versi√≥ 2.0 | Amb mode crawling avan√ßat           ‚ïë\n",
            "        ‚ïë                                                       ‚ïë\n",
            "        ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "        \n",
            "\n",
            "üï∑Ô∏è  CRAWLING DE LLOC WEB COMPLET\n",
            "----------------------------------------\n",
            "\n",
            "üîç Preparant crawling de: https://blocs.xtec.cat/biotecnologia\n",
            "\n",
            "üîÑ Iniciant crawling...\n",
            "üìÑ robots.txt trobat per blocs.xtec.cat\n",
            "üîç Comen√ßant crawling de https://blocs.xtec.cat/biotecnologia\n",
            "   L√≠mit m√†xim de p√†gines: 50\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2026/02/08/index-dequitat-oceanica/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/genetica/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/09/28/longevitat-extrema/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/orpiment/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/plantes/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/mental/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/gens/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/page/2/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/dinamica-molecular/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/migranya/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/15/origen-pla-corporal/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/15/llegir-la-ment/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/alzheimer/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/biomineralitzacio/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/07/del-pare-o-de-la-mare/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/adn-mitocondrial/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/testosterona/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/trans-splicing/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/subgenomes/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/efectes-dorigen-parental/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/amilina/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/glp-1/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/prevencio/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/pintura/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/sintesi-quimica/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/prime-editing/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/hormones/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/quetognats/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/herencia-genetica-materna/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2026/02/08/molta-canya-cientifica/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/estabilitat/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/07/18/prevencio-de-malalties-mitocondrials/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/noguer/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/maquina-molecular/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/floracio/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/07/liti-i-alzheimer/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/malaltia/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/amycretin/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/herencia-asimetrica/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/sulfur/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/denisovans/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/fotoactivacio/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/decodificacio-de-parla/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/07/10/reproduccio-rosa-canina/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/15/tomaquet-mare-de-la-patata/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/2025/08/08/misteri-resolts-de-mendel/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/category/general/\n",
            "   Analitzant: https://blocs.xtec.cat/biotecnologia/tag/duplicacio-genica/\n",
            "‚úÖ Crawling completat. S'han trobat 50 p√†gines.\n",
            "\n",
            "üìä RESULTATS DEL CRAWLING:\n",
            "   ‚Ä¢ P√†gines trobades: 50\n",
            "   ‚Ä¢ P√†gines √∫niques: 50\n",
            "\n",
            "üìù Qu√® vols fer amb les p√†gines trobades?\n",
            "1. Convertir totes a PDF\n",
            "2. Seleccionar manualment\n",
            "3. Guardar llista per despr√©s\n",
            "\n",
            "üîÑ Generant 50 PDFs...\n",
            "   [1/50] Processant: https://blocs.xtec.cat/biotecnologia...\n",
            "     ‚úì PDF generat (287,478 bytes)\n",
            "   [2/50] Processant: https://blocs.xtec.cat/biotecnologia/2026/02/08/index-dequitat-oceanica/...\n",
            "     ‚úì PDF generat (275,155 bytes)\n",
            "   [3/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/genetica/...\n",
            "     ‚úì PDF generat (273,183 bytes)\n",
            "   [4/50] Processant: https://blocs.xtec.cat/biotecnologia/2025/09/28/longevitat-extrema/...\n",
            "     ‚úì PDF generat (278,836 bytes)\n",
            "   [5/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/orpiment/...\n",
            "     ‚úì PDF generat (259,735 bytes)\n",
            "   [6/50] Processant: https://blocs.xtec.cat/biotecnologia/...\n",
            "     ‚úì PDF generat (287,478 bytes)\n",
            "   [7/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/plantes/...\n",
            "     ‚úì PDF generat (259,278 bytes)\n",
            "   [8/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/mental/...\n",
            "     ‚úì PDF generat (259,141 bytes)\n",
            "   [9/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/gens/...\n",
            "     ‚úì PDF generat (259,758 bytes)\n",
            "   [10/50] Processant: https://blocs.xtec.cat/biotecnologia/page/2/...\n",
            "     ‚úì PDF generat (289,767 bytes)\n",
            "   [11/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/dinamica-molecular/...\n",
            "     ‚úì PDF generat (261,266 bytes)\n",
            "   [12/50] Processant: https://blocs.xtec.cat/biotecnologia/tag/migranya/...\n",
            "     ‚úì PDF generat (260,663 bytes)\n",
            "   [13/50] Processant: https://blocs.xtec.cat/biotecnologia/2025/08/15/origen-pla-corporal/...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "SISTEMA AVAN√áAT DE CONVERSI√ì WEB A PDF\n",
        "Per Google Colab - Versi√≥ 2.0\n",
        "\"\"\"\n",
        "\n",
        "# ============ INSTAL¬∑LACI√ì DE DEPEND√àNCIES ============\n",
        "print(\"üîÑ Instal¬∑lant depend√®ncies necess√†ries...\")\n",
        "\n",
        "!apt-get update -qq > /dev/null 2>&1\n",
        "!apt-get install -y -qq wkhtmltopdf > /dev/null 2>&1\n",
        "!pip install -q pdfkit requests beautifulsoup4 PyPDF2 selenium webdriver-manager pillow > /dev/null 2>&1\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from urllib.parse import urlparse, urljoin\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Depend√®ncies instal¬∑lades correctament\")\n",
        "\n",
        "# ============ CONFIGURACI√ì DEL SISTEMA ============\n",
        "class PDFGeneratorConfig:\n",
        "    \"\"\"Configuraci√≥ del sistema de generaci√≥ de PDFs\"\"\"\n",
        "\n",
        "    # Directoris\n",
        "    BASE_DIR = Path(\"/content/pdf_generator\")\n",
        "    TEMP_DIR = BASE_DIR / \"temp\"\n",
        "    OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "    LOGS_DIR = BASE_DIR / \"logs\"\n",
        "\n",
        "    # Par√†metres per defecte\n",
        "    DEFAULT_OPTIONS = {\n",
        "        'page-size': 'A4',\n",
        "        'margin-top': '0.5in',\n",
        "        'margin-right': '0.5in',\n",
        "        'margin-bottom': '0.5in',\n",
        "        'margin-left': '0.5in',\n",
        "        'encoding': 'UTF-8',\n",
        "        'enable-local-file-access': None,\n",
        "        'quiet': '',\n",
        "        'no-outline': None,\n",
        "        'disable-smart-shrinking': None,\n",
        "        'zoom': 1.0,\n",
        "        'custom-header': [\n",
        "            ('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
        "        ],\n",
        "        'javascript-delay': 1000,\n",
        "    }\n",
        "\n",
        "    # Formats suportats\n",
        "    SUPPORTED_FORMATS = ['pdf', 'html', 'png']\n",
        "\n",
        "    def __init__(self):\n",
        "        self.create_directories()\n",
        "\n",
        "    def create_directories(self):\n",
        "        \"\"\"Crea els directoris necessaris\"\"\"\n",
        "        for directory in [self.BASE_DIR, self.TEMP_DIR, self.OUTPUT_DIR, self.LOGS_DIR]:\n",
        "            directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ============ EINES AUXILIARS ============\n",
        "class WebTools:\n",
        "    \"\"\"Eines per al processament web\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_url(url):\n",
        "        \"\"\"Valida i normalitza una URL\"\"\"\n",
        "        if not url.startswith(('http://', 'https://')):\n",
        "            url = 'https://' + url\n",
        "\n",
        "        try:\n",
        "            result = urlparse(url)\n",
        "            if all([result.scheme, result.netloc]):\n",
        "                return url\n",
        "            return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_domain(url):\n",
        "        \"\"\"Extrau el domini d'una URL\"\"\"\n",
        "        return urlparse(url).netloc\n",
        "\n",
        "    @staticmethod\n",
        "    def get_page_title(url):\n",
        "        \"\"\"Obt√© el t√≠tol d'una p√†gina web\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            title = soup.title.string if soup.title else \"Sense t√≠tol\"\n",
        "            return title.strip()[:100]\n",
        "        except:\n",
        "            return \"Document sense t√≠tol\"\n",
        "\n",
        "    @staticmethod\n",
        "    def estimate_reading_time(text_length):\n",
        "        \"\"\"Estima el temps de lectura\"\"\"\n",
        "        words = text_length / 5  # Aproximaci√≥ de paraules\n",
        "        minutes = words / 200  # Velocitat mitjana de lectura\n",
        "        return max(1, int(minutes))\n",
        "\n",
        "# ============ CRAWLER AVAN√áAT ============\n",
        "class AdvancedWebCrawler:\n",
        "    \"\"\"Crawler per descobrir totes les p√†gines d'un lloc\"\"\"\n",
        "\n",
        "    def __init__(self, base_url, max_pages=50, respect_robots=True):\n",
        "        self.base_url = base_url\n",
        "        self.max_pages = max_pages\n",
        "        self.respect_robots = respect_robots\n",
        "        self.visited = set()\n",
        "        self.to_visit = set([base_url])\n",
        "        self.discovered_pages = []\n",
        "        self.domain = urlparse(base_url).netloc\n",
        "        self.robots_txt = None\n",
        "\n",
        "        if respect_robots:\n",
        "            self.fetch_robots_txt()\n",
        "\n",
        "    def fetch_robots_txt(self):\n",
        "        \"\"\"Obt√© el fitxer robots.txt\"\"\"\n",
        "        try:\n",
        "            robots_url = urljoin(self.base_url, '/robots.txt')\n",
        "            response = requests.get(robots_url, timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                self.robots_txt = response.text\n",
        "                print(f\"üìÑ robots.txt trobat per {self.domain}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def is_allowed(self, url):\n",
        "        \"\"\"Comprova si la URL est√† permesa per robots.txt\"\"\"\n",
        "        if not self.robots_txt:\n",
        "            return True\n",
        "\n",
        "        # An√†lisi b√†sic de robots.txt\n",
        "        for line in self.robots_txt.split('\\n'):\n",
        "            if line.lower().startswith('disallow:'):\n",
        "                path = line.split(':', 1)[1].strip()\n",
        "                if path and path in url:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    def extract_links(self, html_content, current_url):\n",
        "        \"\"\"Extrau tots els enlla√ßos d'una p√†gina\"\"\"\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        links = []\n",
        "\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            href = link.get('href')\n",
        "            full_url = urljoin(current_url, href)\n",
        "\n",
        "            # Filtrar enlla√ßos\n",
        "            if self.is_valid_link(full_url):\n",
        "                links.append(full_url)\n",
        "\n",
        "        return links\n",
        "\n",
        "    def is_valid_link(self, url):\n",
        "        \"\"\"Determina si un enlla√ß √©s v√†lid per al crawling\"\"\"\n",
        "        # Nom√©s mateix domini\n",
        "        if urlparse(url).netloc != self.domain:\n",
        "            return False\n",
        "\n",
        "        # Excloure extensions no desitjades\n",
        "        excluded_ext = [\n",
        "            '.pdf', '.jpg', '.jpeg', '.png', '.gif', '.svg',\n",
        "            '.css', '.js', '.zip', '.tar', '.gz', '.exe',\n",
        "            '.mp3', '.mp4', '.avi', '.mov'\n",
        "        ]\n",
        "\n",
        "        if any(url.lower().endswith(ext) for ext in excluded_ext):\n",
        "            return False\n",
        "\n",
        "        # Excloure enlla√ßos especials\n",
        "        if any(x in url.lower() for x in ['mailto:', 'tel:', 'javascript:', '#']):\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def crawl(self):\n",
        "        \"\"\"Executa el crawling del lloc\"\"\"\n",
        "        print(f\"üîç Comen√ßant crawling de {self.base_url}\")\n",
        "        print(f\"   L√≠mit m√†xim de p√†gines: {self.max_pages}\")\n",
        "\n",
        "        while self.to_visit and len(self.visited) < self.max_pages:\n",
        "            current_url = self.to_visit.pop()\n",
        "\n",
        "            if current_url in self.visited:\n",
        "                continue\n",
        "\n",
        "            if not self.is_allowed(current_url):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                print(f\"   Analitzant: {current_url}\")\n",
        "\n",
        "                response = requests.get(current_url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    self.visited.add(current_url)\n",
        "                    self.discovered_pages.append(current_url)\n",
        "\n",
        "                    # Extraure nous enlla√ßos\n",
        "                    new_links = self.extract_links(response.text, current_url)\n",
        "\n",
        "                    for link in new_links:\n",
        "                        if link not in self.visited and link not in self.to_visit:\n",
        "                            self.to_visit.add(link)\n",
        "\n",
        "                    time.sleep(0.5)  # Respectar el servidor\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Error amb {current_url}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"‚úÖ Crawling completat. S'han trobat {len(self.discovered_pages)} p√†gines.\")\n",
        "        return self.discovered_pages\n",
        "\n",
        "# ============ GENERADOR DE PDFS ============\n",
        "class PDFGenerator:\n",
        "    \"\"\"Generador principal de PDFs\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.stats = {\n",
        "            'total_pages': 0,\n",
        "            'successful': 0,\n",
        "            'failed': 0,\n",
        "            'total_size': 0,\n",
        "            'start_time': None,\n",
        "            'end_time': None\n",
        "        }\n",
        "\n",
        "        # Configurar pdfkit\n",
        "        try:\n",
        "            import pdfkit\n",
        "            self.wkhtml_path = '/usr/bin/wkhtmltopdf'\n",
        "            self.pdfkit_config = pdfkit.configuration(wkhtmltopdf=self.wkhtml_path)\n",
        "            self.pdfkit_available = True\n",
        "        except:\n",
        "            self.pdfkit_available = False\n",
        "            print(\"‚ö†Ô∏è  pdfkit no disponible, utilitzant mode alternatiu\")\n",
        "\n",
        "    def generate_single_pdf(self, url, output_path, options=None):\n",
        "        \"\"\"Genera un PDF a partir d'una sola URL\"\"\"\n",
        "        if not self.pdfkit_available:\n",
        "            return self.generate_alternative(url, output_path)\n",
        "\n",
        "        import pdfkit\n",
        "\n",
        "        try:\n",
        "            # Preparar opcions\n",
        "            pdf_options = self.config.DEFAULT_OPTIONS.copy()\n",
        "            if options:\n",
        "                pdf_options.update(options)\n",
        "\n",
        "            # Generar PDF\n",
        "            pdfkit.from_url(url, output_path,\n",
        "                          configuration=self.pdfkit_config,\n",
        "                          options=pdf_options)\n",
        "\n",
        "            # Verificar resultat\n",
        "            if os.path.exists(output_path) and os.path.getsize(output_path) > 1024:\n",
        "                size = os.path.getsize(output_path)\n",
        "                self.stats['successful'] += 1\n",
        "                self.stats['total_size'] += size\n",
        "                return True, size\n",
        "            else:\n",
        "                return False, 0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Error generant PDF: {e}\")\n",
        "            return False, 0\n",
        "\n",
        "    def generate_alternative(self, url, output_path):\n",
        "        \"\"\"M√®tode alternatiu per generar PDFs\"\"\"\n",
        "        try:\n",
        "            from selenium import webdriver\n",
        "            from webdriver_manager.chrome import ChromeDriverManager\n",
        "            from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "            # Configurar Chrome headless\n",
        "            chrome_options = Options()\n",
        "            chrome_options.add_argument('--headless')\n",
        "            chrome_options.add_argument('--no-sandbox')\n",
        "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "            chrome_options.add_argument('--disable-gpu')\n",
        "            chrome_options.add_argument('--window-size=1920,1080')\n",
        "\n",
        "            # Instal¬∑lar i configurar driver\n",
        "            driver = webdriver.Chrome(\n",
        "                ChromeDriverManager().install(),\n",
        "                options=chrome_options\n",
        "            )\n",
        "\n",
        "            # Capturar p√†gina\n",
        "            driver.get(url)\n",
        "            time.sleep(3)  # Esperar a que carregui\n",
        "\n",
        "            # Guardar com a PDF (Chrome headless t√© aquesta opci√≥)\n",
        "            pdf_data = driver.execute_cdp_cmd('Page.printToPDF', {\n",
        "                'landscape': False,\n",
        "                'displayHeaderFooter': False,\n",
        "                'printBackground': True,\n",
        "                'preferCSSPageSize': True,\n",
        "            })\n",
        "\n",
        "            import base64\n",
        "            with open(output_path, 'wb') as f:\n",
        "                f.write(base64.b64decode(pdf_data['data']))\n",
        "\n",
        "            driver.quit()\n",
        "\n",
        "            size = os.path.getsize(output_path)\n",
        "            self.stats['successful'] += 1\n",
        "            self.stats['total_size'] += size\n",
        "            return True, size\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Error en m√®tode alternatiu: {e}\")\n",
        "            return False, 0\n",
        "\n",
        "    def generate_batch(self, urls, output_filename, merge=True, progress_callback=None):\n",
        "        \"\"\"Genera PDFs per a m√∫ltiples URLs\"\"\"\n",
        "        self.stats['start_time'] = datetime.now()\n",
        "        self.stats['total_pages'] = len(urls)\n",
        "\n",
        "        print(f\"\\nüîÑ Generant {len(urls)} PDFs...\")\n",
        "\n",
        "        # Crear directori temporal\n",
        "        temp_dir = self.config.TEMP_DIR / f\"batch_{int(time.time())}\"\n",
        "        temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        generated_files = []\n",
        "\n",
        "        for i, url in enumerate(urls, 1):\n",
        "            if progress_callback:\n",
        "                progress_callback(i, len(urls))\n",
        "\n",
        "            print(f\"   [{i}/{len(urls)}] Processant: {url[:80]}...\")\n",
        "\n",
        "            # Generar nom de fitxer segur\n",
        "            safe_name = self.get_safe_filename(url)\n",
        "            temp_pdf = temp_dir / f\"{i:03d}_{safe_name}.pdf\"\n",
        "\n",
        "            # Generar PDF\n",
        "            success, size = self.generate_single_pdf(url, str(temp_pdf))\n",
        "\n",
        "            if success:\n",
        "                generated_files.append(temp_pdf)\n",
        "                print(f\"     ‚úì PDF generat ({size:,} bytes)\")\n",
        "            else:\n",
        "                self.stats['failed'] += 1\n",
        "                print(f\"     ‚úó Error generant PDF\")\n",
        "\n",
        "            time.sleep(1)  # Pausa per no sobrecarregar\n",
        "\n",
        "        # Combinar PDFs si √©s necessari\n",
        "        if merge and len(generated_files) > 1:\n",
        "            final_path = self.merge_pdfs(generated_files, output_filename)\n",
        "        elif generated_files:\n",
        "            final_path = generated_files[0]\n",
        "            os.rename(final_path, self.config.OUTPUT_DIR / output_filename)\n",
        "        else:\n",
        "            final_path = None\n",
        "\n",
        "        # Actualitzar estad√≠stiques\n",
        "        self.stats['end_time'] = datetime.now()\n",
        "        self.generate_report()\n",
        "\n",
        "        # Netejar fitxers temporals\n",
        "        self.cleanup_temp(temp_dir)\n",
        "\n",
        "        return final_path\n",
        "\n",
        "    def merge_pdfs(self, pdf_files, output_filename):\n",
        "        \"\"\"Combina m√∫ltiples PDFs en un sol fitxer\"\"\"\n",
        "        try:\n",
        "            from PyPDF2 import PdfMerger\n",
        "\n",
        "            merger = PdfMerger()\n",
        "            output_path = self.config.OUTPUT_DIR / output_filename\n",
        "\n",
        "            for pdf_file in pdf_files:\n",
        "                merger.append(str(pdf_file))\n",
        "\n",
        "            merger.write(str(output_path))\n",
        "            merger.close()\n",
        "\n",
        "            print(f\"\\n‚úÖ PDFs combinats correctament: {output_filename}\")\n",
        "            return output_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error combinant PDFs: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_safe_filename(self, url):\n",
        "        \"\"\"Crea un nom de fitxer segur a partir d'una URL\"\"\"\n",
        "        from urllib.parse import urlparse\n",
        "        import re\n",
        "\n",
        "        # Extraure parts de la URL\n",
        "        parsed = urlparse(url)\n",
        "        path = parsed.path.strip('/').replace('/', '_')\n",
        "        domain = parsed.netloc.replace('.', '_')\n",
        "\n",
        "        # Netejar car√†cters no v√†lids\n",
        "        filename = f\"{domain}_{path}\" if path else domain\n",
        "        filename = re.sub(r'[^\\w\\-_\\. ]', '_', filename)\n",
        "        filename = filename[:100]  # Limitar longitud\n",
        "\n",
        "        return filename if filename else \"document\"\n",
        "\n",
        "    def cleanup_temp(self, temp_dir):\n",
        "        \"\"\"Neteja els fitxers temporals\"\"\"\n",
        "        import shutil\n",
        "        try:\n",
        "            shutil.rmtree(temp_dir)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"Genera un informe d'execuci√≥\"\"\"\n",
        "        duration = self.stats['end_time'] - self.stats['start_time']\n",
        "\n",
        "        report = f\"\"\"\n",
        "        üìä INFORME DE GENERACI√ì DE PDF\n",
        "        =================================\n",
        "        ‚Ä¢ Data i hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "        ‚Ä¢ P√†gines processades: {self.stats['total_pages']}\n",
        "        ‚Ä¢ √àxits: {self.stats['successful']}\n",
        "        ‚Ä¢ Errors: {self.stats['failed']}\n",
        "        ‚Ä¢ Temps total: {duration.total_seconds():.1f} segons\n",
        "        ‚Ä¢ Mida total: {self.stats['total_size']:,} bytes\n",
        "        =================================\n",
        "        \"\"\"\n",
        "\n",
        "        print(report)\n",
        "\n",
        "        # Guardar informe\n",
        "        report_file = self.config.LOGS_DIR / f\"report_{int(time.time())}.txt\"\n",
        "        with open(report_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(report)\n",
        "\n",
        "# ============ INTERF√çCIE D'USUARI ============\n",
        "class PDFGeneratorUI:\n",
        "    \"\"\"Interf√≠cie d'usuari per al sistema\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.config = PDFGeneratorConfig()\n",
        "        self.tools = WebTools()\n",
        "        self.generator = PDFGenerator(self.config)\n",
        "        self.current_project = None\n",
        "\n",
        "    def display_banner(self):\n",
        "        \"\"\"Mostra el banner del sistema\"\"\"\n",
        "        banner = \"\"\"\n",
        "        ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        ‚ïë                                                       ‚ïë\n",
        "        ‚ïë    üåê SISTEMA DE CONVERSI√ì WEB A PDF                 ‚ïë\n",
        "        ‚ïë          per Google Colab                            ‚ïë\n",
        "        ‚ïë                                                       ‚ïë\n",
        "        ‚ïë    Versi√≥ 2.0 | Amb mode crawling avan√ßat           ‚ïë\n",
        "        ‚ïë                                                       ‚ïë\n",
        "        ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        \"\"\"\n",
        "        print(banner)\n",
        "\n",
        "    def display_menu(self):\n",
        "        \"\"\"Mostra el men√∫ principal\"\"\"\n",
        "        menu = \"\"\"\n",
        "        üìã MENU PRINCIPAL:\n",
        "\n",
        "        1. üéØ Convertir una sola p√†gina web\n",
        "        2. üìù Convertir una llista d'URLs\n",
        "        3. üï∑Ô∏è  Convertir tot un lloc web (crawling)\n",
        "        4. üìä Veure informes anteriors\n",
        "        5. ‚öôÔ∏è  Configurar opcions avan√ßades\n",
        "        6. üìö Ajuda i exemples\n",
        "        7. üö™ Sortir\n",
        "\n",
        "        Escull una opci√≥ (1-7): \"\"\"\n",
        "\n",
        "        return input(menu).strip()\n",
        "\n",
        "    def option_single_page(self):\n",
        "        \"\"\"Opci√≥ 1: Convertir una sola p√†gina\"\"\"\n",
        "        print(\"\\nüéØ CONVERTIR UNA SOLA P√ÄGINA WEB\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        url = input(\"Introdueix la URL de la p√†gina: \").strip()\n",
        "        validated_url = self.tools.validate_url(url)\n",
        "\n",
        "        if not validated_url:\n",
        "            print(\"‚ùå URL inv√†lida. Torna-ho a provar.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüîç Analitzant: {validated_url}\")\n",
        "\n",
        "        try:\n",
        "            # Obtindre informaci√≥ de la p√†gina\n",
        "            title = self.tools.get_page_title(validated_url)\n",
        "            domain = self.tools.extract_domain(validated_url)\n",
        "\n",
        "            print(f\"   T√≠tol: {title}\")\n",
        "            print(f\"   Domini: {domain}\")\n",
        "\n",
        "            # Demanar nom del fitxer\n",
        "            default_name = self.generator.get_safe_filename(validated_url)\n",
        "            filename = input(f\"\\nüìù Nom del fitxer PDF [{default_name}.pdf]: \").strip()\n",
        "            filename = filename if filename else f\"{default_name}.pdf\"\n",
        "\n",
        "            if not filename.endswith('.pdf'):\n",
        "                filename += '.pdf'\n",
        "\n",
        "            # Configurar opcions\n",
        "            print(\"\\n‚öôÔ∏è  Configuraci√≥ (prem Enter per valors per defecte):\")\n",
        "\n",
        "            page_size = input(f\"   Mida de p√†gina [A4]: \").strip() or 'A4'\n",
        "            orientation = input(f\"   Orientaci√≥ [portrait/landscape]: \").strip() or 'portrait'\n",
        "\n",
        "            options = {\n",
        "                'page-size': page_size,\n",
        "                'orientation': orientation,\n",
        "            }\n",
        "\n",
        "            print(f\"\\nüîÑ Convertint {validated_url} a PDF...\")\n",
        "\n",
        "            output_path = self.config.OUTPUT_DIR / filename\n",
        "            success, size = self.generator.generate_single_pdf(\n",
        "                validated_url,\n",
        "                str(output_path),\n",
        "                options\n",
        "            )\n",
        "\n",
        "            if success:\n",
        "                print(f\"\\n‚úÖ PDF generat correctament!\")\n",
        "                print(f\"   Fitxer: {filename}\")\n",
        "                print(f\"   Mida: {size:,} bytes\")\n",
        "                print(f\"   Ubicaci√≥: {output_path}\")\n",
        "\n",
        "                self.offer_download(output_path)\n",
        "            else:\n",
        "                print(\"‚ùå Error generant el PDF. Torna-ho a provar.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    def option_url_list(self):\n",
        "        \"\"\"Opci√≥ 2: Convertir una llista d'URLs\"\"\"\n",
        "        print(\"\\nüìù CONVERTIR UNA LLISTA D'URLs\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        print(\"\\nPots introduir URLs de les seg√ºents maneres:\")\n",
        "        print(\"1. Directament aqu√≠ (una per l√≠nia)\")\n",
        "        print(\"2. Desde un fitxer de text\")\n",
        "        print(\"3. Desde un fitxer JSON\")\n",
        "\n",
        "        choice = input(\"\\nEscull una opci√≥ (1-3): \").strip()\n",
        "\n",
        "        urls = []\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\nüì• Introdueix les URLs (una per l√≠nia).\")\n",
        "            print(\"   Escriu 'END' en una l√≠nia nova per acabar:\")\n",
        "\n",
        "            while True:\n",
        "                url = input().strip()\n",
        "                if url.upper() == 'END':\n",
        "                    break\n",
        "                if url:\n",
        "                    validated = self.tools.validate_url(url)\n",
        "                    if validated:\n",
        "                        urls.append(validated)\n",
        "                        print(f\"   ‚úì URL afegida: {validated[:80]}...\")\n",
        "                    else:\n",
        "                        print(f\"   ‚úó URL inv√†lida: {url}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\nüì§ Pujant fitxer de text...\")\n",
        "            from google.colab import files\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            for filename, content in uploaded.items():\n",
        "                if filename.endswith('.txt'):\n",
        "                    lines = content.decode('utf-8').split('\\n')\n",
        "                    urls = [self.tools.validate_url(line.strip())\n",
        "                           for line in lines if line.strip()]\n",
        "                    urls = [u for u in urls if u]  # Eliminar None\n",
        "                    break\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\nüì§ Pujant fitxer JSON...\")\n",
        "            from google.colab import files\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            for filename, content in uploaded.items():\n",
        "                if filename.endswith('.json'):\n",
        "                    try:\n",
        "                        data = json.loads(content.decode('utf-8'))\n",
        "                        if isinstance(data, list):\n",
        "                            urls = [self.tools.validate_url(url) for url in data]\n",
        "                            urls = [u for u in urls if u]\n",
        "                    except:\n",
        "                        print(\"‚ùå Error llegint el fitxer JSON\")\n",
        "\n",
        "        if not urls:\n",
        "            print(\"‚ùå No s'han trobat URLs v√†lides.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n‚úÖ S'han trobat {len(urls)} URLs v√†lides.\")\n",
        "\n",
        "        # Configuraci√≥\n",
        "        filename = input(\"\\nüìù Nom del fitxer PDF final [llista_webs.pdf]: \").strip()\n",
        "        filename = filename if filename else \"llista_webs.pdf\"\n",
        "\n",
        "        merge = input(\"\\nüìë Vols combinar tot en un sol PDF? (s/n) [s]: \").strip().lower()\n",
        "        merge = merge != 'n'\n",
        "\n",
        "        # Generar PDFs\n",
        "        print(f\"\\nüîÑ Convertint {len(urls)} p√†gines a PDF...\")\n",
        "\n",
        "        output_path = self.generator.generate_batch(\n",
        "            urls,\n",
        "            filename,\n",
        "            merge=merge,\n",
        "            progress_callback=lambda i, total: print(f\"   Processant {i}/{total}...\")\n",
        "        )\n",
        "\n",
        "        if output_path:\n",
        "            self.offer_download(output_path)\n",
        "\n",
        "    def option_crawl_site(self):\n",
        "        \"\"\"Opci√≥ 3: Crawling de tot un lloc web\"\"\"\n",
        "        print(\"\\nüï∑Ô∏è  CRAWLING DE LLOC WEB COMPLET\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        url = input(\"Introdueix la URL inicial: \").strip()\n",
        "        validated_url = self.tools.validate_url(url)\n",
        "\n",
        "        if not validated_url:\n",
        "            print(\"‚ùå URL inv√†lida.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüîç Preparant crawling de: {validated_url}\")\n",
        "\n",
        "        # Configuraci√≥ del crawling\n",
        "        max_pages = input(f\"   M√†xim de p√†gines a analitzar [50]: \").strip()\n",
        "        max_pages = int(max_pages) if max_pages.isdigit() else 50\n",
        "\n",
        "        respect_robots = input(f\"   Respectar robots.txt? (s/n) [s]: \").strip().lower()\n",
        "        respect_robots = respect_robots != 'n'\n",
        "\n",
        "        # Executar crawling\n",
        "        print(f\"\\nüîÑ Iniciant crawling...\")\n",
        "\n",
        "        crawler = AdvancedWebCrawler(\n",
        "            validated_url,\n",
        "            max_pages=max_pages,\n",
        "            respect_robots=respect_robots\n",
        "        )\n",
        "\n",
        "        discovered_urls = crawler.crawl()\n",
        "\n",
        "        if not discovered_urls:\n",
        "            print(\"‚ùå No s'han trobat p√†gines.\")\n",
        "            return\n",
        "\n",
        "        # Mostrar resultats\n",
        "        print(f\"\\nüìä RESULTATS DEL CRAWLING:\")\n",
        "        print(f\"   ‚Ä¢ P√†gines trobades: {len(discovered_urls)}\")\n",
        "        print(f\"   ‚Ä¢ P√†gines √∫niques: {len(set(discovered_urls))}\")\n",
        "\n",
        "        # Demanar qu√® fer amb els resultats\n",
        "        print(\"\\nüìù Qu√® vols fer amb les p√†gines trobades?\")\n",
        "        print(\"1. Convertir totes a PDF\")\n",
        "        print(\"2. Seleccionar manualment\")\n",
        "        print(\"3. Guardar llista per despr√©s\")\n",
        "\n",
        "        action = input(\"Escull una opci√≥ (1-3): \").strip()\n",
        "\n",
        "        if action == '1':\n",
        "            filename = input(\"\\nNom del fitxer PDF [lloc_complet.pdf]: \").strip()\n",
        "            filename = filename if filename else \"lloc_complet.pdf\"\n",
        "\n",
        "            output_path = self.generator.generate_batch(\n",
        "                discovered_urls,\n",
        "                filename,\n",
        "                merge=True\n",
        "            )\n",
        "\n",
        "            if output_path:\n",
        "                self.offer_download(output_path)\n",
        "\n",
        "        elif action == '2':\n",
        "            print(\"\\nüìã P√†gines trobades:\")\n",
        "            for i, url in enumerate(discovered_urls[:20], 1):\n",
        "                print(f\"{i:3d}. {url[:80]}...\")\n",
        "\n",
        "            if len(discovered_urls) > 20:\n",
        "                print(f\"... i {len(discovered_urls) - 20} m√©s\")\n",
        "\n",
        "            selected = input(\"\\nIntrodueix els n√∫meros separats per comes: \").strip()\n",
        "            indices = [int(i.strip()) - 1 for i in selected.split(',') if i.strip().isdigit()]\n",
        "\n",
        "            selected_urls = [discovered_urls[i] for i in indices if i < len(discovered_urls)]\n",
        "\n",
        "            if selected_urls:\n",
        "                filename = input(\"\\nNom del fitxer PDF [seleccio.pdf]: \").strip()\n",
        "                filename = filename if filename else \"seleccio.pdf\"\n",
        "\n",
        "                output_path = self.generator.generate_batch(selected_urls, filename)\n",
        "\n",
        "                if output_path:\n",
        "                    self.offer_download(output_path)\n",
        "\n",
        "    def option_view_reports(self):\n",
        "        \"\"\"Opci√≥ 4: Veure informes anteriors\"\"\"\n",
        "        print(\"\\nüìä INFORMES ANTERIORS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        reports = list(self.config.LOGS_DIR.glob(\"*.txt\"))\n",
        "\n",
        "        if not reports:\n",
        "            print(\"No hi ha informes disponibles.\")\n",
        "            return\n",
        "\n",
        "        reports.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "\n",
        "        print(f\"\\nüìÅ S'han trobat {len(reports)} informes:\")\n",
        "\n",
        "        for i, report in enumerate(reports[:10], 1):\n",
        "            mtime = datetime.fromtimestamp(report.stat().st_mtime)\n",
        "            size = report.stat().st_size\n",
        "\n",
        "            print(f\"{i:2d}. {report.name}\")\n",
        "            print(f\"    Data: {mtime.strftime('%Y-%m-%d %H:%M')}\")\n",
        "            print(f\"    Mida: {size:,} bytes\")\n",
        "            print()\n",
        "\n",
        "        view = input(\"Veure algun informe? (n√∫mero o 'n' per cap): \").strip()\n",
        "\n",
        "        if view.isdigit():\n",
        "            idx = int(view) - 1\n",
        "            if 0 <= idx < len(reports):\n",
        "                with open(reports[idx], 'r', encoding='utf-8') as f:\n",
        "                    print(f\"\\n{'='*50}\")\n",
        "                    print(f.read())\n",
        "                    print(f\"{'='*50}\")\n",
        "\n",
        "    def offer_download(self, file_path):\n",
        "        \"\"\"Ofereix la desc√†rrega d'un fitxer\"\"\"\n",
        "        print(f\"\\nüì• DESCARREGA DEL FITXER\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(\"‚ùå El fitxer no existeix.\")\n",
        "            return\n",
        "\n",
        "        size = os.path.getsize(file_path)\n",
        "        print(f\"Fitxer: {os.path.basename(file_path)}\")\n",
        "        print(f\"Mida: {size:,} bytes ({size/1024/1024:.2f} MB)\")\n",
        "\n",
        "        download = input(\"\\nVols descarregar el fitxer ara? (s/n) [s]: \").strip().lower()\n",
        "\n",
        "        if download != 'n':\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                files.download(str(file_path))\n",
        "                print(\"‚úÖ Descarrega iniciada!\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error en la desc√†rrega: {e}\")\n",
        "                print(f\"üìÅ El fitxer est√† a: {file_path}\")\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Executa la interf√≠cie principal\"\"\"\n",
        "        self.display_banner()\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                choice = self.display_menu()\n",
        "\n",
        "                if choice == '1':\n",
        "                    self.option_single_page()\n",
        "                elif choice == '2':\n",
        "                    self.option_url_list()\n",
        "                elif choice == '3':\n",
        "                    self.option_crawl_site()\n",
        "                elif choice == '4':\n",
        "                    self.option_view_reports()\n",
        "                elif choice == '5':\n",
        "                    print(\"\\n‚öôÔ∏è  Configuraci√≥ avan√ßada... (en desenvolupament)\")\n",
        "                elif choice == '6':\n",
        "                    self.show_help()\n",
        "                elif choice == '7' or choice.lower() == 'exit':\n",
        "                    print(\"\\nüëã Fins aviat!\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"\\n‚ùå Opci√≥ inv√†lida. Torna-ho a provar.\")\n",
        "\n",
        "                input(\"\\nPrem Enter per continuar...\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n\\nüëã Execuci√≥ interrompuda. Fins aviat!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ùå Error inesperat: {e}\")\n",
        "\n",
        "    def show_help(self):\n",
        "        \"\"\"Mostra l'ajuda i exemples\"\"\"\n",
        "        help_text = \"\"\"\n",
        "        üìö AJUDA I EXEMPLES\n",
        "\n",
        "        1. FORMATS D'ENTRADA ACCEPTATS:\n",
        "           ‚Ä¢ URLs individuals: https://exemple.com\n",
        "           ‚Ä¢ Llistes en text pla: una URL per l√≠nia\n",
        "           ‚Ä¢ JSON: array d'URLs\n",
        "\n",
        "        2. OPCIONS DE CONFIGURACI√ì:\n",
        "           ‚Ä¢ Mida de p√†gina: A4, Letter, Legal, etc.\n",
        "           ‚Ä¢ Orientaci√≥: portrait o landscape\n",
        "           ‚Ä¢ Marges: personalitzables\n",
        "\n",
        "        3. MODE CRAWLING:\n",
        "           ‚Ä¢ Analitza tot un lloc web autom√†ticament\n",
        "           ‚Ä¢ Respecta robots.txt (opcional)\n",
        "           ‚Ä¢ L√≠mit configurable de p√†gines\n",
        "\n",
        "        4. EXEMPLES DE US:\n",
        "           ‚Ä¢ Convertir article: https://exemple.com/article\n",
        "           ‚Ä¢ Convertir blog: mode crawling\n",
        "           ‚Ä¢ Convertir llista: URLs de cursos/articles\n",
        "\n",
        "        5. CONSELLS:\n",
        "           ‚Ä¢ Per a p√†gines amb JavaScript, el sistema\n",
        "             utilitza un motor alternatiu\n",
        "           ‚Ä¢ Pots ajustar el temps d'espera si les\n",
        "             p√†gines s√≥n lentes a carregar\n",
        "        \"\"\"\n",
        "\n",
        "        print(help_text)\n",
        "\n",
        "# ============ INICIALITZACI√ì ============\n",
        "def main():\n",
        "    \"\"\"Funci√≥ principal d'inicialitzaci√≥\"\"\"\n",
        "    print(\"üîß Inicialitzant sistema de conversi√≥ web a PDF...\")\n",
        "\n",
        "    # Crear i executar la interf√≠cie\n",
        "    ui = PDFGeneratorUI()\n",
        "    ui.run()\n",
        "\n",
        "# Executar el sistema\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP_iPR0PIJjM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('openair_book_complete.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLaSmQu6H9pq",
        "outputId": "c59f329b-e150-4912-b2ad-6ac789796d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Extracting templates from packages: 100%\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libavahi-client3_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking libavahi-client3:amd64 (0.8-5ubuntu5.4) over (0.8-5ubuntu5.3) ...\n",
            "Preparing to unpack .../01-libavahi-common3_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking libavahi-common3:amd64 (0.8-5ubuntu5.4) over (0.8-5ubuntu5.3) ...\n",
            "Preparing to unpack .../02-libavahi-common-data_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking libavahi-common-data:amd64 (0.8-5ubuntu5.4) over (0.8-5ubuntu5.3) ...\n",
            "Selecting previously unselected package libavahi-core7:amd64.\n",
            "Preparing to unpack .../03-libavahi-core7_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.4) ...\n",
            "Selecting previously unselected package libdaemon0:amd64.\n",
            "Preparing to unpack .../04-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n",
            "Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Selecting previously unselected package avahi-daemon.\n",
            "Preparing to unpack .../05-avahi-daemon_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking avahi-daemon (0.8-5ubuntu5.4) ...\n",
            "Selecting previously unselected package libdouble-conversion3:amd64.\n",
            "Preparing to unpack .../06-libdouble-conversion3_3.1.7-4_amd64.deb ...\n",
            "Unpacking libdouble-conversion3:amd64 (3.1.7-4) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../07-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../08-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../09-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../10-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../11-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../12-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../13-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../14-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../15-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../16-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../17-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../18-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../19-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../20-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../21-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../22-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../23-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../24-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../25-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../26-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../27-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../28-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../29-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package liborc-0.4-0:amd64.\n",
            "Preparing to unpack .../30-liborc-0.4-0_1%3a0.4.32-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking liborc-0.4-0:amd64 (1:0.4.32-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libgstreamer-plugins-base1.0-0:amd64.\n",
            "Preparing to unpack .../31-libgstreamer-plugins-base1.0-0_1.20.1-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking libgstreamer-plugins-base1.0-0:amd64 (1.20.1-1ubuntu0.5) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../32-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libqt5positioning5:amd64.\n",
            "Preparing to unpack .../33-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n",
            "Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../34-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5qml5:amd64.\n",
            "Preparing to unpack .../35-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5qmlmodels5:amd64.\n",
            "Preparing to unpack .../36-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5quick5:amd64.\n",
            "Preparing to unpack .../37-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5sensors5:amd64.\n",
            "Preparing to unpack .../38-libqt5sensors5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5webchannel5:amd64.\n",
            "Preparing to unpack .../39-libqt5webchannel5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../40-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libqt5webkit5:amd64.\n",
            "Preparing to unpack .../41-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../42-udev_249.11-0ubuntu3.17_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.17) ...\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "Preparing to unpack .../43-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../44-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../45-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../46-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../47-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package libavahi-glib1:amd64.\n",
            "Preparing to unpack .../48-libavahi-glib1_0.8-5ubuntu5.4_amd64.deb ...\n",
            "Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.4) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../49-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../50-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libmm-glib0:amd64.\n",
            "Preparing to unpack .../51-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../52-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../53-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../54-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../55-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../56-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../57-libsoup2.4-common_2.74.2-3ubuntu0.6_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.6) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../58-libsoup2.4-1_2.74.2-3ubuntu0.6_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\n",
            "Selecting previously unselected package geoclue-2.0.\n",
            "Preparing to unpack .../59-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n",
            "Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Selecting previously unselected package libcdparanoia0:amd64.\n",
            "Preparing to unpack .../60-libcdparanoia0_3.10.2+debian-14build2_amd64.deb ...\n",
            "Unpacking libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\n",
            "Selecting previously unselected package libvisual-0.4-0:amd64.\n",
            "Preparing to unpack .../61-libvisual-0.4-0_0.4.0-17build2_amd64.deb ...\n",
            "Unpacking libvisual-0.4-0:amd64 (0.4.0-17build2) ...\n",
            "Selecting previously unselected package gstreamer1.0-plugins-base:amd64.\n",
            "Preparing to unpack .../62-gstreamer1.0-plugins-base_1.20.1-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.5) ...\n",
            "Selecting previously unselected package iio-sensor-proxy.\n",
            "Preparing to unpack .../63-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n",
            "Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../64-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../65-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../66-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../67-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libgtk-3-common.\n",
            "Preparing to unpack .../68-libgtk-3-common_3.24.33-1ubuntu2.2_all.deb ...\n",
            "Unpacking libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-0:amd64.\n",
            "Preparing to unpack .../69-libgtk-3-0_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-bin.\n",
            "Preparing to unpack .../70-libgtk-3-bin_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libmbim-glib4:amd64.\n",
            "Preparing to unpack .../71-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libmbim-proxy.\n",
            "Preparing to unpack .../72-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libnl-genl-3-200:amd64.\n",
            "Preparing to unpack .../73-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n",
            "Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Selecting previously unselected package libnss-mdns:amd64.\n",
            "Preparing to unpack .../74-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libqmi-glib5:amd64.\n",
            "Preparing to unpack .../75-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libqmi-proxy.\n",
            "Preparing to unpack .../76-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../77-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../78-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package modemmanager.\n",
            "Preparing to unpack .../79-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../80-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../81-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../82-systemd-hwe-hwdb_249.11.6_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.6) ...\n",
            "Selecting previously unselected package wpasupplicant.\n",
            "Preparing to unpack .../83-wpasupplicant_2%3a2.10-6ubuntu2.3_amd64.deb ...\n",
            "Unpacking wpasupplicant (2:2.10-6ubuntu2.3) ...\n",
            "Selecting previously unselected package usb-modeswitch-data.\n",
            "Preparing to unpack .../84-usb-modeswitch-data_20191128-4_all.deb ...\n",
            "Unpacking usb-modeswitch-data (20191128-4) ...\n",
            "Selecting previously unselected package usb-modeswitch.\n",
            "Preparing to unpack .../85-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Selecting previously unselected package wkhtmltopdf.\n",
            "Preparing to unpack .../86-wkhtmltopdf_0.12.6-2_amd64.deb ...\n",
            "Unpacking wkhtmltopdf (0.12.6-2) ...\n",
            "Setting up libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service ‚Üí /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libdouble-conversion3:amd64 (3.1.7-4) ...\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up libvisual-0.4-0:amd64 (0.4.0-17build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up libavahi-common-data:amd64 (0.8-5ubuntu5.4) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up usb-modeswitch-data (20191128-4) ...\n",
            "Setting up udev (249.11-0ubuntu3.17) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up liborc-0.4-0:amd64 (1:0.4.32-2ubuntu0.1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.6) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.6) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "First installation detected...\n",
            "Checking NSS setup...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Setting up libavahi-common3:amd64 (0.8-5ubuntu5.4) ...\n",
            "Setting up libgstreamer-plugins-base1.0-0:amd64 (1.20.1-1ubuntu0.5) ...\n",
            "Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up wpasupplicant (2:2.10-6ubuntu2.3) ...\n",
            "Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service ‚Üí /lib/systemd/system/wpa_supplicant.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service ‚Üí /lib/systemd/system/wpa_supplicant.service.\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.5) ...\n",
            "Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.4) ...\n",
            "Setting up libavahi-core7:amd64 (0.8-5ubuntu5.4) ...\n",
            "Setting up libavahi-client3:amd64 (0.8-5ubuntu5.4) ...\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up avahi-daemon (0.8-5ubuntu5.4) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of force-reload.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service ‚Üí /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service ‚Üí /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket ‚Üí /lib/systemd/system/avahi-daemon.socket.\n",
            "Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Setting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service ‚Üí /lib/systemd/system/ModemManager.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service ‚Üí /lib/systemd/system/ModemManager.service.\n",
            "Setting up wkhtmltopdf (0.12.6-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.7) ...\n",
            "Setting up libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Setting up libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\n",
            "Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hüîç Obtenint llista de cap√≠tols...\n",
            "\n",
            "üìö Trobades 34 p√†gines:\n",
            "  1. https://openair-project.github.io/book/\n",
            "  2. https://openair-project.github.io/book/index.html\n",
            "  3. https://openair-project.github.io/book/sections/appendices/appendix-annotate.html\n",
            "  4. https://openair-project.github.io/book/sections/appendices/appendix-gethelp.html\n",
            "  5. https://openair-project.github.io/book/sections/appendices/appendix-hysplit.html\n",
            "  6. https://openair-project.github.io/book/sections/appendices/appendix-trends.html\n",
            "  7. https://openair-project.github.io/book/sections/data-access/UK-air-quality-data.html\n",
            "  8. https://openair-project.github.io/book/sections/data-access/access-met-data.html\n",
            "  9. https://openair-project.github.io/book/sections/directional-analysis/percentile-roses.html\n",
            "  10. https://openair-project.github.io/book/sections/directional-analysis/polar-annulus.html\n",
            "  ... i 24 m√©s\n",
            "\n",
            "üîÑ Convertint a PDF...\n",
            "Processant (1/34): https://openair-project.github.io/book/\n",
            "  ‚úì PDF generat (1208781 bytes)\n",
            "Processant (2/34): https://openair-project.github.io/book/index.html\n",
            "  ‚úì PDF generat (1208781 bytes)\n",
            "Processant (3/34): https://openair-project.github.io/book/sections/appendices/appendix-annotate.html\n",
            "  ‚úì PDF generat (3649152 bytes)\n",
            "Processant (4/34): https://openair-project.github.io/book/sections/appendices/appendix-gethelp.html\n",
            "  ‚úì PDF generat (1641297 bytes)\n",
            "Processant (5/34): https://openair-project.github.io/book/sections/appendices/appendix-hysplit.html\n",
            "  ‚úì PDF generat (1016755 bytes)\n",
            "Processant (6/34): https://openair-project.github.io/book/sections/appendices/appendix-trends.html\n",
            "  ‚úì PDF generat (3129624 bytes)\n",
            "Processant (7/34): https://openair-project.github.io/book/sections/data-access/UK-air-quality-data.html\n",
            "  ‚úì PDF generat (3349537 bytes)\n",
            "Processant (8/34): https://openair-project.github.io/book/sections/data-access/access-met-data.html\n",
            "  ‚úì PDF generat (1140215 bytes)\n",
            "Processant (9/34): https://openair-project.github.io/book/sections/directional-analysis/percentile-roses.html\n",
            "  ‚úì PDF generat (2629620 bytes)\n",
            "Processant (10/34): https://openair-project.github.io/book/sections/directional-analysis/polar-annulus.html\n",
            "  ‚úì PDF generat (1142380 bytes)\n",
            "Processant (11/34): https://openair-project.github.io/book/sections/directional-analysis/polar-freq.html\n",
            "  ‚úì PDF generat (3310949 bytes)\n",
            "Processant (12/34): https://openair-project.github.io/book/sections/directional-analysis/polar-plots.html\n",
            "  ‚úì PDF generat (19093032 bytes)\n",
            "Processant (13/34): https://openair-project.github.io/book/sections/directional-analysis/trajectory-analysis.html\n",
            "  ‚úì PDF generat (18580473 bytes)\n",
            "Processant (14/34): https://openair-project.github.io/book/sections/directional-analysis/wind-roses.html\n",
            "  ‚úì PDF generat (5172645 bytes)\n",
            "Processant (15/34): https://openair-project.github.io/book/sections/intro/intro.html\n",
            "  ‚úì PDF generat (589419 bytes)\n",
            "Processant (16/34): https://openair-project.github.io/book/sections/intro/openair-package.html\n",
            "  ‚úì PDF generat (6778528 bytes)\n",
            "Processant (17/34): https://openair-project.github.io/book/sections/maps/maps-network.html\n",
            "  ‚úì PDF generat (2189045 bytes)\n",
            "Processant (18/34): https://openair-project.github.io/book/sections/maps/maps-overview.html\n",
            "  ‚úì PDF generat (1619328 bytes)\n",
            "Processant (19/34): https://openair-project.github.io/book/sections/maps/maps-polar.html\n",
            "  ‚úì PDF generat (4165264 bytes)\n",
            "Processant (20/34): https://openair-project.github.io/book/sections/maps/maps-traj.html\n",
            "  ‚úì PDF generat (1188733 bytes)\n",
            "Processant (21/34): https://openair-project.github.io/book/sections/model-evaluation/conditional-quantiles.html\n",
            "  ‚úì PDF generat (5802649 bytes)\n",
            "Processant (22/34): https://openair-project.github.io/book/sections/model-evaluation/mod-stats.html\n",
            "  ‚úì PDF generat (2671548 bytes)\n",
            "Processant (23/34): https://openair-project.github.io/book/sections/model-evaluation/taylor-diagram.html\n",
            "  ‚úì PDF generat (3008229 bytes)\n",
            "Processant (24/34): https://openair-project.github.io/book/sections/references.html\n",
            "  ‚úì PDF generat (3129083 bytes)\n",
            "Processant (25/34): https://openair-project.github.io/book/sections/trend-analysis/calendar-plot.html\n",
            "  ‚úì PDF generat (4009739 bytes)\n",
            "Processant (26/34): https://openair-project.github.io/book/sections/trend-analysis/run-regression.html\n",
            "  ‚úì PDF generat (2999173 bytes)\n",
            "Processant (27/34): https://openair-project.github.io/book/sections/trend-analysis/smooth-trend.html\n",
            "  ‚úì PDF generat (3773167 bytes)\n",
            "Processant (28/34): https://openair-project.github.io/book/sections/trend-analysis/theil-sen.html\n",
            "  ‚úì PDF generat (4741936 bytes)\n",
            "Processant (29/34): https://openair-project.github.io/book/sections/trend-analysis/time-plot.html\n",
            "  ‚úì PDF generat (2887426 bytes)\n",
            "Processant (30/34): https://openair-project.github.io/book/sections/trend-analysis/time-proportion.html\n",
            "  ‚úì PDF generat (1011218 bytes)\n",
            "Processant (31/34): https://openair-project.github.io/book/sections/trend-analysis/time-variation.html\n",
            "  ‚úì PDF generat (6218935 bytes)\n",
            "Processant (32/34): https://openair-project.github.io/book/sections/trend-analysis/trend-level.html\n",
            "  ‚úì PDF generat (3963574 bytes)\n",
            "Processant (33/34): https://openair-project.github.io/book/sections/utilities/scatter-plot.html\n",
            "  ‚úì PDF generat (4208470 bytes)\n",
            "Processant (34/34): https://openair-project.github.io/book/sections/utilities/utility-functions.html\n",
            "  ‚úì PDF generat (6609204 bytes)\n",
            "\n",
            "Combinant 34 PDFs en un sol fitxer...\n",
            "\n",
            "‚úÖ PDF complet generat: openair_book_complete.pdf\n",
            "   Mida del fitxer: 137806953 bytes\n",
            "\n",
            "üì• Per descarregar el PDF, executa: files.download('openair_book_complete.pdf')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instal¬∑lem les depend√®ncies necess√†ries\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq wkhtmltopdf\n",
        "!pip install -q pdfkit requests beautifulsoup4 PyPDF2\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import pdfkit\n",
        "import time\n",
        "import os\n",
        "from PyPDF2 import PdfMerger\n",
        "\n",
        "def get_all_chapter_urls(start_url):\n",
        "    \"\"\"Obt√© totes les URLs del llibre\"\"\"\n",
        "    response = requests.get(start_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    chapters = []\n",
        "\n",
        "    # Buscar tots els enlla√ßos que s√≥n part del llibre\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link.get('href')\n",
        "        if href:\n",
        "            # Ignorar enlla√ßos externs i ancores\n",
        "            if href.startswith('http') and 'openair-project.github.io/book/' not in href:\n",
        "                continue\n",
        "            if href.startswith('#'):\n",
        "                continue\n",
        "\n",
        "            # Construir URL completa\n",
        "            full_url = urljoin(start_url, href)\n",
        "\n",
        "            # Filtrar per obtenir nom√©s p√†gines del llibre\n",
        "            if 'openair-project.github.io/book/' in full_url:\n",
        "                # Excloure recursos no HTML\n",
        "                excluded_extensions = ['.css', '.js', '.png', '.jpg', '.jpeg', '.gif', '.svg']\n",
        "                if not any(full_url.lower().endswith(ext) for ext in excluded_extensions):\n",
        "                    # Normalitzar URL (eliminar fragments)\n",
        "                    full_url = full_url.split('#')[0]\n",
        "                    if full_url not in chapters:\n",
        "                        chapters.append(full_url)\n",
        "\n",
        "    return chapters\n",
        "\n",
        "def convert_urls_to_pdf(urls, output_file):\n",
        "    \"\"\"Converteix m√∫ltiples URLs a un sol PDF\"\"\"\n",
        "    # Configurar opcions per a PDF\n",
        "    options = {\n",
        "        'page-size': 'A4',\n",
        "        'margin-top': '0.5in',\n",
        "        'margin-right': '0.5in',\n",
        "        'margin-bottom': '0.5in',\n",
        "        'margin-left': '0.5in',\n",
        "        'encoding': 'UTF-8',\n",
        "        'no-outline': None,\n",
        "        'enable-local-file-access': None,  # Important per a Colab\n",
        "        'quiet': ''\n",
        "    }\n",
        "\n",
        "    # Configurar pdfkit per a Colab (wkhtmltopdf s'instal¬∑la a /usr/bin/)\n",
        "    config = pdfkit.configuration(wkhtmltopdf='/usr/bin/wkhtmltopdf')\n",
        "\n",
        "    # Crear directori per als PDFs temporals\n",
        "    os.makedirs('temp_pdfs', exist_ok=True)\n",
        "\n",
        "    # Convertir cada p√†gina a PDF\n",
        "    pdf_files = []\n",
        "    successful_conversions = 0\n",
        "\n",
        "    for i, url in enumerate(urls):\n",
        "        try:\n",
        "            print(f\"Processant ({i+1}/{len(urls)}): {url}\")\n",
        "            output_filename = f\"temp_pdfs/chapter_{i}.pdf\"\n",
        "\n",
        "            # Convertir la p√†gina a PDF\n",
        "            pdfkit.from_url(url, output_filename, options=options, configuration=config)\n",
        "\n",
        "            # Verificar que el PDF s'ha generat correctament\n",
        "            if os.path.exists(output_filename) and os.path.getsize(output_filename) > 0:\n",
        "                pdf_files.append(output_filename)\n",
        "                successful_conversions += 1\n",
        "                print(f\"  ‚úì PDF generat ({os.path.getsize(output_filename)} bytes)\")\n",
        "            else:\n",
        "                print(f\"  ‚úó Error: PDF buit o no generat\")\n",
        "\n",
        "            time.sleep(0.5)  # Esperar per no sobrecarregar el servidor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó Error processant {url}: {str(e)[:100]}...\")\n",
        "\n",
        "    # Combinar tots els PDFs en un sol fitxer\n",
        "    if pdf_files:\n",
        "        print(f\"\\nCombinant {successful_conversions} PDFs en un sol fitxer...\")\n",
        "        merger = PdfMerger()\n",
        "\n",
        "        for pdf_file in pdf_files:\n",
        "            try:\n",
        "                merger.append(pdf_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error afegint {pdf_file}: {e}\")\n",
        "\n",
        "        # Guardar el PDF final\n",
        "        merger.write(output_file)\n",
        "        merger.close()\n",
        "\n",
        "        # Netejar fitxers temporals\n",
        "        for pdf_file in pdf_files:\n",
        "            try:\n",
        "                os.remove(pdf_file)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Eliminar directori temporal\n",
        "        try:\n",
        "            os.rmdir('temp_pdfs')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        print(f\"\\n‚úÖ PDF complet generat: {output_file}\")\n",
        "        print(f\"   Mida del fitxer: {os.path.getsize(output_file)} bytes\")\n",
        "\n",
        "        # Mostrar enlla√ß per descarregar a Colab\n",
        "        from google.colab import files\n",
        "        print(\"\\nüì• Per descarregar el PDF, executa: files.download('openair_book_complete.pdf')\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\n‚ùå No s'ha generat cap PDF. Revisa els errors.\")\n",
        "\n",
        "# Executar el script\n",
        "if __name__ == \"__main__\":\n",
        "    start_url = \"https://openair-project.github.io/book/\"\n",
        "\n",
        "    print(\"üîç Obtenint llista de cap√≠tols...\")\n",
        "    chapters = get_all_chapter_urls(start_url)\n",
        "\n",
        "    # Afegir la p√†gina principal si no hi √©s\n",
        "    if start_url not in chapters:\n",
        "        chapters.insert(0, start_url)\n",
        "\n",
        "    # Ordenar URLs per mantenir l'estructura l√≤gica (opcional)\n",
        "    chapters = sorted(set(chapters))  # Eliminar duplicats\n",
        "\n",
        "    print(f\"\\nüìö Trobades {len(chapters)} p√†gines:\")\n",
        "    for i, url in enumerate(chapters[:10]):  # Mostrar les 10 primeres\n",
        "        print(f\"  {i+1}. {url}\")\n",
        "    if len(chapters) > 10:\n",
        "        print(f\"  ... i {len(chapters)-10} m√©s\")\n",
        "\n",
        "    print(f\"\\nüîÑ Convertint a PDF...\")\n",
        "    convert_urls_to_pdf(chapters, \"openair_book_complete.pdf\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaOniyV2x1ErON8S/kInOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}